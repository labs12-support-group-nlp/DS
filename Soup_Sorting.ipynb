{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1622"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_soup = pickle.load(open('group_soup.pkl', 'br'))\n",
    "str(group_soup[45]).count('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new list of only pages with content\n",
    "\n",
    "def clean_pages(list = group_soup):\n",
    "    clean_list =  []\n",
    "    for i in range(0, len(list)):\n",
    "        if str(list[i]).count('/') >= 10:\n",
    "            clean_list.append(list[i])\n",
    "    return clean_list\n",
    "\n",
    "group_soup = clean_pages()\n",
    "len(group_soup)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45389"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def post_num (soup = group_soup):\n",
    "    pnum = re.split(r'^(.+?)}', str(soup))\n",
    "    pnum = re.findall(r\"\\d+\", str(pnum[1]))\n",
    "    pnum = pnum[1::2]\n",
    "    post_number = []\n",
    "    for i in range (0,len(pnum)-1):\n",
    "        post_number.append (pnum[i])\n",
    "        post = re.findall (pnum[i] + r'(.*?)' + pnum[i+1], str(pnum[2]))\n",
    "    return post_number\n",
    "\n",
    "def all_post_num():\n",
    "    pn = []\n",
    "    for i in range (0, 870):\n",
    "        pn.append(post_num(group_soup[i]))\n",
    "    return pn\n",
    "\n",
    "post_num = list(itertools.chain.from_iterable(all_post_num()))\n",
    "len(post_num)\n",
    "        \n",
    "#groups_df1 = pd.DataFrame({'post_number': post_number, 'post_soup' : post_soup})\n",
    "#pickle.dump(groups_df1, open('post_soup2.pkl', 'bw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract list of post numbers and soup to create df\n",
    "\n",
    "def post_soup (soup = group_soup):\n",
    "    post_num = re.split(r'^(.+?)}', str(soup))\n",
    "    gnum = re.findall(r\"\\d+\", str(post_num[1]))\n",
    "    grp_num = gnum[1::2]\n",
    "    post_number = []\n",
    "    post_soup = []\n",
    "    for i in range (0,(len(grp_num)-1)):\n",
    "        post_number.append (grp_num[i])\n",
    "        post = re.findall (grp_num[i] + r'(.*?)' + grp_num[i+1], str(post_num[2]))\n",
    "        post_soup.append (post)\n",
    "    return post_soup\n",
    "\n",
    "def all_post_soup():\n",
    "    ps = []\n",
    "    for i in range (0, 870):\n",
    "        ps.append(post_soup(group_soup[i]))\n",
    "    return ps\n",
    "\n",
    "post_soup = list(itertools.chain.from_iterable(all_post_soup()))\n",
    "len(post_soup)\n",
    "        \n",
    "#groups_df1 = pd.DataFrame({'post_number': post_number, 'post_soup' : post_soup})\n",
    "#pickle.dump(groups_df1, open('post_soup2.pkl', 'bw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_extract(ps = post_soup):\n",
    "    post_only = []\n",
    "    for i in range(0, len(ps)):\n",
    "        select = re.findall (r'activity-item-body-text-(.*?)activity-item-info-', str(ps[i]))\n",
    "        trim = re.findall (r'u003E(.*?)u003C', str(select))\n",
    "        trim = str(trim).replace('\\\\', '')\n",
    "        trim = str(trim).replace('nt', '')\n",
    "        post_only.append(trim)\n",
    "    return post_only\n",
    "\n",
    "post_txt = post_extract()\n",
    "len(post_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issue_extract(ps = post_soup):\n",
    "    groups_only = []\n",
    "    for i in range(0, len(ps)):\n",
    "        select = re.findall (r'u003E in(.*?)u003C', str(ps[i]))\n",
    "        trim = str(select).replace('\\\\', '')\n",
    "        trim = str(trim).replace('nt', '')\n",
    "        groups_only.append(trim)\n",
    "    return groups_only\n",
    "\n",
    "groups = issue_extract()\n",
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine listst for all groups into df\n",
    "\n",
    "sg_df = pd.DataFrame({'post_number': post_num, 'post_txt' : post_txt, 'groups' : groups})\n",
    "pickle.dump(sg_df, open('sg_post_df.pkl', 'bw'))\n",
    "sg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
